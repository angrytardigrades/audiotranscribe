import whisper
import os
import time
import torch

# ✅ Auto-detect GPU if available, else use CPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"\U0001F4E5 Loading Whisper model on {device.upper()}...")

# ✅ Load Whisper model (use "small" for faster speed if needed)
model_size = "medium"
model = whisper.load_model(model_size, device=device)
print(f"✅ Model '{model_size}' loaded successfully!\n")

# 🎙️ **SET YOUR AUDIO FILE PATH HERE**
audio_path = "YOUR AUDIO FILE PATH - EXACT PATH"

# ✅ Check if file exists
if not os.path.exists(audio_path):
    raise FileNotFoundError(f"❌ Error: Audio file not found at {audio_path}")

# ✅ Create output directory
output_dir = os.path.join(os.path.dirname(audio_path), "OUTPUT PATH")
os.makedirs(output_dir, exist_ok=True)

# ✅ Generate output file name
output_file = os.path.join(output_dir, os.path.basename(audio_path).replace(".mp3", ".txt"))

try:
    print("🎙️ Transcription in progress... (this may take a while)\n")

    # ⏳ Start timer
    start_time = time.time()

    # ✅ Transcribe audio (no timestamps)
    result = model.transcribe(audio_path, word_timestamps=False, verbose=True)  

    # ⏱️ End timer
    elapsed_time = time.time() - start_time

    # ✅ Ensure transcription has content
    if "text" not in result or not result["text"].strip():
        raise ValueError("❌ No transcription found! Check if the audio has clear speech.")

    # ✅ Save transcription (no timestamps)
    print(f"📄 Saving transcription to: {output_file}")
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(result["text"] + "\n")

    print(f"\n✅ Transcription finished in {elapsed_time:.2f} seconds.")
    print(f"📂 Transcription saved at: {output_file}")

except Exception as e:
    print(f"\n❌ Error during transcription: {e}")
